# Evolution #2 Data Management

## What do you know? - General:
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Data management is one of the pillars/evolutions I feel the most confident in my knowledge of. The data management process at its purest base is focused around, cleaning, normalizing, storing, updating and retrieving data. One of the biggest factors in being adept at data management, similar to analytics, is a strong working knowledge of the business and the related data that will be managed.  While there are a few different programs that can be used to complete this work, the one I am most comfortable with is SQL. Which stands for structured query language which is used for relational databases. To explain this means that the information stored in this database is stored in multiple tables that all have various levels of relationships with each other. Each table is specific to one ‘area’ of data, like customers, orders, or products. Each table has a primary key which is a unique identifier for each table which is used to identify the specific record of a table. For example, a customers table may have a customer ID number as the primary key, this ID is unique for each individual customer and makes it quick and easy to identify specific customers. Another use of primary keys outside of being a unique identifier is that they can be used to establish and identify relationships between tables. Primary keys can be listed under other tables where they are not the primary key as foreign keys, again this helps establish a relationship between the two tables but then can be used to identify how/where values in one table line up with another. To bring back the customer table/customer ID example, if that same database had an orders table, customer ID would be the field to use as a foreign key in the orders table just as the Order ID from the orders table would be used as a foreign key in the customer table. There are multiple ways to demonstrate and show these relationships within the non relational database model, including one to one, one to many, and then many to many. It is important to understand the database you are trying to create and manage as that allows you to best structure your SQL database. These structures can be seen further in the crows feet diagram attached in this repository, this diagram shows each table, their keys and the relationship between each table.
### What do you know? - Programs and Systems:
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;There are a few products that can help manage SQL databases, luckily they all use the same SQL programming language. The one I am most familiar with is MYSQL. I have gained the major foundation of my SQL experience from CIDM 6350. During this course I learned the flow of planning, creating, populating and updating a SQL database. As noted above, the first step is to create a layout of tables, fields and relationships. We used crow's foot notation in 6350. [[Crow's Foot Example]](https://github.com/nanauman/Evolution2/blob/main/SQL%20Examples/Final%20Project%20Crow's%20Foot%20ERD%20Nathan%20Nauman.pdf) Once the layout is complete, you can then use the MYSQL interface to create the database itself and then to create database tables.[[Creation Example]](https://github.com/nanauman/Evolution2/blob/main/SQL%20Examples/Final%20Project%20Task%20A.2%20Nathan%20Nauman.sql) At this step you also create the fields of each table, here you can also specify the type of field, add constraints and set the default value to null.  Once all tables and fields are created, the next step would be to move to creating users and granting permissions to users. You can do this by granting individual users different permissions or by creating roles, applying permissions to the roles and then tying individuals to certain roles.[[Role Creation & Permissions Example]](https://github.com/nanauman/Evolution2/blob/main/SQL%20Examples/Final%20Project%20Task%20B%20Nathan%20Nauman.sql) The latter being the ideal for larger organizations where multiple users of different roles will be using the database as you can grant permission to the table level as well as the individual field level. Now the database is ready for actual data data can be uploaded via CSV file using the SQL coding interface, or via INSERT INTO statements using the SQL coding interface.[[Insert example]](https://github.com/nanauman/Evolution2/blob/main/SQL%20Examples/Final%20Project%20Task%20C2%20Nathan%20Nauman.sql) The coding interface allows for multiple lines to be added to a table at a time or single lines. As shown in the example above it is also possible to update specific fields in tables using the UPDATE statement. Once data has been added to tables, you are then able to pull info from tables using the SELECT statement.[[Select Statement Example]](https://github.com/nanauman/Evolution2/blob/main/SQL%20Examples/Final%20Project%20Task%20C3%20Nathan%20Nauman%20(1).pdf)The select statement allows for certain parameters to be specified to narrow down results that are pulled, like in the SELECT example above IQ1 is only bringing back the Customer IDs where the remaining balance is over 500. You are also able to delete individual rows, tables, or even the entire database using the DELETE statement. Another useful feature of SQL database management systems is the JOIN function. This process allows for data from different tables to be pulled at the same time together. There are a few different types of joins including right, left inner and outer, these allow for data to be grouped together in different ways. Similar to SELECT statements JOINS give users the ability to narrow down results to their needs. Now it is important to note data must first be normalized and cleaned in order to be ingested into a SQL database. SQL databases can also be connected to a network server allowing the database servers to be accessed via web connection. I have had experience connecting a database to a web server in CIDM 5310 (link). 

&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;As I mentioned in the first section, data management also includes the cleaning and normalization of data. This is the process of removing any redundant, missing or null values from ‘dirty’ data pulled from data sources,  as well as standardizing data in terms of scale and time if necessary. The SQL examples  One of the more useful programs in normalizing data, outside of the obvious Microsoft Excel or Google Sheets, would be to use Python and one of the associated packages like NUMPY or Pandas. Both of these Python packages can be useful in managing and cleaning large sets of data and then are stored in their respective formats(arrays for NUMPY and dataframes for Pandas). Using these Python packages can also lead to easier visualization of the data, using Python as well. I gained my experience on these packages from CIDM 5310 and the Pandas assignments (Link) I have done in that course as well as taking the SoloLearn course Python for Data Science in course CIDM 6351.(link)

## Where are you weak?
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;My biggest weakness is NO SQL databases, including MongoDB. While I am aware why they are used, for non-relational databases, I am not familiar with that actual structure or how to manage these types of databases. I see this as an enormous opportunity for my skill set, as it is unrealistic to assume every database will be relational. This is certainly an aspect I want to fold into some degree in my final project in order to get more first-hand experience. 

## What don’t you know?:
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;My biggest blindspot would be other database structures outside of SQL and NOSQL databases. From my initial research I cannot see a situation that would not be covered by either the relational database (SQL) model or the NOSQL model, however there have to be some specific type databases that do not follow under either model. Additionally I would love to learn more about managing extremely large databases in large organizations with lots of users to monitor and high volumes of different types of data to manage.    

## Integration with the other 3 evolutions:
### &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; Evolution #1: Data Analytics:
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Starting with analytics, in the vast majority of situations any data that will be analyzed will first be stored and organized within some  form of database local to the organization. In order to make analysis easier and more efficient it is important that data is accessible, organized and uniform. This not only helps in terms of ease, but also helps lead to more accurate analysis which in turn would lead to a higher level of organizational success. Individuals conducting analysis can use the data management software itself (like MYSQL) to pull the appropriate data they need to look at or there are even opportunities to have integration between the analytical system and the database. This allows the analytical system, like Tableau for instance, to pull the data from the databases automatically and then allow the user to use Tableau’s interface to conduct analysis quicker than if the individual had to pull data themselves.

### &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; Evolution #3: Software and Systems:
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Data management interacts with software systems in a myriad of ways. First off, the obvious need for data management software but it goes far past that, including the example above with a data analysis program pulling from databases automatically. Also included in this relationship would be any software that collects data and then feeds into the database for storage. An example of this would be order or transaction management software, this software would be used to execute customer transactions while also sending transaction and customer data to appropriate databases. This is just one example of how these two evolutions interact and there are limitless possibilities for other interactions. In general, most software systems will feed into a database of somesort, there are few interactions in the business world that do not feature some form of record that feeds to a database.

### &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; Evolution #4: Network and Cyber Security:
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Data management is intertwined with network and cyber security in a few ways, first off as noted above databases can be held on a web connected server, which automatically opens the database, and equally importantly the data itself, to all kinds of potential cyber attacks. If a database is connected to a network it is open to any potential weaknesses across the network. A lot of information stored in organization’s databases are personal and sensitive in nature, particularly customer information. There are also certain laws and standards that are required when dealing with customer information however this is not exclusive to network based databases as it applies to locally based databases. One of the largest things to be aware of when dealing with exclusively local databases would be physical security as that is the biggest potential weakness. In today’s business world a vast majority of databases are connected in some way to a network. Almost all network connected database management systems feature some security features however each individual organization will want to make sure that they have their own security measure in place at the base of which is creating logins for users and granting permissions / access to specific databases based on user needs. Additional standard cybersecurity practices, like monitoring port statuses, checking for potential vulnerabilities, keeping all software up to date, and having backup and recovery plans all play a role in protecting database data. The last detail regarding backup and recovery plans are extremely vital to databases specifically as they are a way to retrieve any lost or corrupted data. Data that without these contingency plans could be lost with detrimental consequences to organizations. Security practices help protect data and databases as well as provide a means to recover any data stored in databases if a negative security event were to occur.

